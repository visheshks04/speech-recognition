{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpeechRecognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJEeUftpETp5"
      },
      "source": [
        "!rm -r sample_data"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znLsp21pwIkY",
        "outputId": "d4907232-dc36-4d96-f6cf-f5f67efb82c8"
      },
      "source": [
        "!pip install virtualenv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.9.0-py2.py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 43.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (4.8.1)\n",
            "Collecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.4.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: six<2,>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (1.15.0)\n",
            "Collecting backports.entry-points-selectable>=1.0.4\n",
            "  Downloading backports.entry_points_selectable-1.1.0-py2.py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: filelock<4,>=3.2 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (3.3.0)\n",
            "Collecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.3-py2.py3-none-any.whl (496 kB)\n",
            "\u001b[K     |████████████████████████████████| 496 kB 55.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->virtualenv) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->virtualenv) (3.6.0)\n",
            "Installing collected packages: platformdirs, distlib, backports.entry-points-selectable, virtualenv\n",
            "Successfully installed backports.entry-points-selectable-1.1.0 distlib-0.3.3 platformdirs-2.4.0 virtualenv-20.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPpNprKmvzAH",
        "outputId": "a28155d0-232b-4be5-f3ff-0109b6eb5fdf"
      },
      "source": [
        "!virtualenv speechrecognition.venv"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created virtual environment CPython3.7.12.final.0-64 in 739ms\n",
            "  creator CPython3Posix(dest=/content/speechrecognition.venv, clear=False, no_vcs_ignore=False, global=False)\n",
            "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n",
            "    added seed packages: pip==21.3.1, setuptools==58.3.0, wheel==0.37.0\n",
            "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8ZmQYCjwXWN"
      },
      "source": [
        "!source speechrecognition.venv/bin/activate"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5LMxuKgVoGw",
        "outputId": "57f14b30-3cf7-4655-9a9f-406af2fbdf02"
      },
      "source": [
        "#Update link\n",
        "!wget 'https://raw.githubusercontent.com/visheshks04/speech-recognition/master/data/captions_data.json'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-27 09:11:02--  https://raw.githubusercontent.com/visheshks04/speech-recognition/master/data/captions_data.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 132177 (129K) [text/plain]\n",
            "Saving to: ‘captions_data.json’\n",
            "\n",
            "\rcaptions_data.json    0%[                    ]       0  --.-KB/s               \rcaptions_data.json  100%[===================>] 129.08K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2021-10-27 09:11:02 (61.8 MB/s) - ‘captions_data.json’ saved [132177/132177]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCVZ9EN3f-4G"
      },
      "source": [
        "## Requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWC4Xu8HWFgk",
        "outputId": "815b1df8-473e-4194-869d-7734754264c0"
      },
      "source": [
        "!pip3 install pytube"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-11.0.1-py3-none-any.whl (56 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▉                          | 10 kB 26.8 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 20 kB 30.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 30 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 40 kB 36.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 51 kB 40.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 56 kB 4.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-11.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT8HS3qSyXTN",
        "outputId": "94ff3e63-91f6-4312-c786-3e8addacbe82"
      },
      "source": [
        "# Update link\n",
        "!wget 'https://raw.githubusercontent.com/visheshks04/A-Hackers-AI-Voice-Assistant/master/requirements.txt'"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-27 09:24:28--  https://raw.githubusercontent.com/visheshks04/A-Hackers-AI-Voice-Assistant/master/requirements.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 779 [text/plain]\n",
            "Saving to: ‘requirements.txt’\n",
            "\n",
            "\rrequirements.txt      0%[                    ]       0  --.-KB/s               \rrequirements.txt    100%[===================>]     779  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-27 09:24:28 (47.9 MB/s) - ‘requirements.txt’ saved [779/779]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqUamIHABNuA"
      },
      "source": [
        "f1 = open('requirements.txt', 'r')\n",
        "f2 = open('new_requirements.txt', 'w')\n",
        "\n",
        "for line in f1.readlines():\n",
        "  f2.write(line.split('==')[0]+'\\n')\n",
        "\n",
        "f1.close()\n",
        "f2.close()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6R6BgBsyoLV",
        "outputId": "a7878434-9bec-45cd-e8f5-046593fafa4e"
      },
      "source": [
        "!pip install -r new_requirements.txt"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 1)) (1.6.3)\n",
            "Requirement already satisfied: audioread in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 2)) (2.1.9)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 3)) (2021.5.30)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 5)) (0.3.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 6)) (3.3.0)\n",
            "Collecting fsspec\n",
            "  Downloading fsspec-2021.10.1-py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 37.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 8)) (0.16.0)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 9)) (0.4.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 10)) (1.0.1)\n",
            "Requirement already satisfied: Keras-Preprocessing in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 11)) (1.1.2)\n",
            "Requirement already satisfied: llvmlite in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 12)) (0.34.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 13)) (3.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 14)) (3.2.5)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 15)) (0.51.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 16)) (1.19.5)\n",
            "Requirement already satisfied: oauthlib in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 17)) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 18)) (1.1.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 19)) (7.1.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 20)) (3.17.3)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-1.4.9-py3-none-any.whl (925 kB)\n",
            "\u001b[K     |████████████████████████████████| 925 kB 42.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 23)) (2019.12.20)\n",
            "Requirement already satisfied: resampy in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 24)) (0.2.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 42.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 26)) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 27)) (1.4.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 28)) (0.11.2)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 45.5 MB/s \n",
            "\u001b[?25hCollecting sonopy\n",
            "  Downloading sonopy-0.1.2.tar.gz (3.3 kB)\n",
            "Requirement already satisfied: SoundFile in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 31)) (0.10.3.post1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 32)) (0.8.9)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 33)) (2.6.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 34)) (1.8.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 35)) (2.6.0)\n",
            "Requirement already satisfied: tensorflow-estimator in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 36)) (2.6.0)\n",
            "Collecting tokenizers\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 39.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 38)) (1.9.0+cu111)\n",
            "Collecting torchaudio\n",
            "  Downloading torchaudio-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 45.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 40)) (0.10.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 41)) (0.10.0+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 42)) (4.62.3)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 42.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from -r new_requirements.txt (line 44)) (3.7.4.3)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from astunparse->-r new_requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse->-r new_requirements.txt (line 1)) (0.37.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r new_requirements.txt (line 13)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r new_requirements.txt (line 13)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r new_requirements.txt (line 13)) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r new_requirements.txt (line 13)) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->-r new_requirements.txt (line 15)) (57.4.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r new_requirements.txt (line 18)) (2018.9)\n",
            "Collecting PyYAML>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 49.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning->-r new_requirements.txt (line 22)) (21.0)\n",
            "Collecting future\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 50.2 MB/s \n",
            "\u001b[?25hCollecting pyDeprecate==0.3.1\n",
            "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
            "Collecting torchmetrics>=0.4.0\n",
            "  Downloading torchmetrics-0.5.1-py3-none-any.whl (282 kB)\n",
            "\u001b[K     |████████████████████████████████| 282 kB 51.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r new_requirements.txt (line 33)) (2.23.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r new_requirements.txt (line 33)) (0.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r new_requirements.txt (line 33)) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r new_requirements.txt (line 33)) (1.41.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r new_requirements.txt (line 33)) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r new_requirements.txt (line 33)) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r new_requirements.txt (line 33)) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r new_requirements.txt (line 33)) (0.6.1)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 45.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r new_requirements.txt (line 33)) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r new_requirements.txt (line 33)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r new_requirements.txt (line 33)) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r new_requirements.txt (line 33)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->-r new_requirements.txt (line 33)) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->-r new_requirements.txt (line 33)) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r new_requirements.txt (line 33)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r new_requirements.txt (line 33)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r new_requirements.txt (line 33)) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->-r new_requirements.txt (line 25)) (7.1.2)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from SoundFile->-r new_requirements.txt (line 31)) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->SoundFile->-r new_requirements.txt (line 31)) (2.20)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r new_requirements.txt (line 35)) (1.1.0)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r new_requirements.txt (line 35)) (2.6.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r new_requirements.txt (line 35)) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r new_requirements.txt (line 35)) (1.12)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r new_requirements.txt (line 35)) (1.12.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r new_requirements.txt (line 35)) (0.2.0)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r new_requirements.txt (line 35)) (5.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r new_requirements.txt (line 35)) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow->-r new_requirements.txt (line 35)) (1.5.2)\n",
            "Collecting torch\n",
            "  Downloading torch-1.10.0-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
            "\u001b[K     |██████████████████████████████▎ | 834.1 MB 1.3 MB/s eta 0:00:38tcmalloc: large alloc 1147494400 bytes == 0x564f16cd0000 @  0x7ff436e39615 0x564edcdb34cc 0x564edce9347a 0x564edcdb62ed 0x564edcea7e1d 0x564edce29e99 0x564edce249ee 0x564edcdb7bda 0x564edce29d00 0x564edce249ee 0x564edcdb7bda 0x564edce26737 0x564edcea8c66 0x564edce25daf 0x564edcea8c66 0x564edce25daf 0x564edcea8c66 0x564edce25daf 0x564edcdb8039 0x564edcdfb409 0x564edcdb6c52 0x564edce29c25 0x564edce249ee 0x564edcdb7bda 0x564edce26737 0x564edce249ee 0x564edcdb7bda 0x564edce25915 0x564edcdb7afa 0x564edce25c0d 0x564edce249ee\n",
            "\u001b[K     |████████████████████████████████| 881.9 MB 16 kB/s \n",
            "\u001b[?25hCollecting torchtext\n",
            "  Downloading torchtext-0.11.0-cp37-cp37m-manylinux1_x86_64.whl (8.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.0 MB 17.2 MB/s \n",
            "\u001b[?25hCollecting torchvision\n",
            "  Downloading torchvision-0.11.1-cp37-cp37m-manylinux1_x86_64.whl (23.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.3 MB 81 kB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 3.8 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 52.1 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 47.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec->-r new_requirements.txt (line 7)) (21.2.0)\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->-r new_requirements.txt (line 33)) (3.6.0)\n",
            "Building wheels for collected packages: future, sonopy\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=b1bd9320efe252e0b63812d64be7049658a374b626a0909b8c1be8633531a7bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "  Building wheel for sonopy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sonopy: filename=sonopy-0.1.2-py3-none-any.whl size=2878 sha256=e46240eed9289498f326318811c2739707a83115caabe2c5992f70e2c6df3c5d\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/17/02/d430779ebe878618c57368f50b0a7d6f4c9efc957e762290a9\n",
            "Successfully built future sonopy\n",
            "Installing collected packages: multidict, yarl, async-timeout, torch, PyYAML, fsspec, aiohttp, torchmetrics, tokenizers, sacremoses, pyDeprecate, huggingface-hub, future, transformers, torchvision, torchtext, torchaudio, sonopy, sentencepiece, pytorch-lightning, pydub, dataclasses\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu111\n",
            "    Uninstalling torch-1.9.0+cu111:\n",
            "      Successfully uninstalled torch-1.9.0+cu111\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.10.0+cu111\n",
            "    Uninstalling torchvision-0.10.0+cu111:\n",
            "      Successfully uninstalled torchvision-0.10.0+cu111\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.10.0\n",
            "    Uninstalling torchtext-0.10.0:\n",
            "      Successfully uninstalled torchtext-0.10.0\n",
            "Successfully installed PyYAML-6.0 aiohttp-3.7.4.post0 async-timeout-3.0.1 dataclasses-0.6 fsspec-2021.10.1 future-0.18.2 huggingface-hub-0.0.19 multidict-5.2.0 pyDeprecate-0.3.1 pydub-0.25.1 pytorch-lightning-1.4.9 sacremoses-0.0.46 sentencepiece-0.1.96 sonopy-0.1.2 tokenizers-0.10.3 torch-1.10.0 torchaudio-0.10.0 torchmetrics-0.5.1 torchtext-0.11.0 torchvision-0.11.1 transformers-4.11.3 yarl-1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRUHw7gKHOj2"
      },
      "source": [
        "#!pip install torch==1.5.0"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpEiAeEzXGbQ",
        "outputId": "0298176d-4a30-49ed-a774-482c7ae8fcb2"
      },
      "source": [
        "!git clone --recursive https://github.com/parlance/ctcdecode.git"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ctcdecode'...\n",
            "remote: Enumerating objects: 1102, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 1102 (delta 16), reused 28 (delta 13), pack-reused 1063\u001b[K\n",
            "Receiving objects: 100% (1102/1102), 780.91 KiB | 14.73 MiB/s, done.\n",
            "Resolving deltas: 100% (529/529), done.\n",
            "Submodule 'third_party/ThreadPool' (https://github.com/progschj/ThreadPool.git) registered for path 'third_party/ThreadPool'\n",
            "Submodule 'third_party/kenlm' (https://github.com/kpu/kenlm.git) registered for path 'third_party/kenlm'\n",
            "Cloning into '/content/ctcdecode/third_party/ThreadPool'...\n",
            "remote: Enumerating objects: 82, done.        \n",
            "remote: Total 82 (delta 0), reused 0 (delta 0), pack-reused 82        \n",
            "Cloning into '/content/ctcdecode/third_party/kenlm'...\n",
            "remote: Enumerating objects: 14047, done.        \n",
            "remote: Counting objects: 100% (360/360), done.        \n",
            "remote: Compressing objects: 100% (292/292), done.        \n",
            "remote: Total 14047 (delta 107), reused 121 (delta 55), pack-reused 13687        \n",
            "Receiving objects: 100% (14047/14047), 5.76 MiB | 18.08 MiB/s, done.\n",
            "Resolving deltas: 100% (7987/7987), done.\n",
            "Submodule path 'third_party/ThreadPool': checked out '9a42ec1329f259a5f4881a291db1dcb8f2ad9040'\n",
            "Submodule path 'third_party/kenlm': checked out '35835f1ac4884126458ac89f9bf6dd9ccad561e0'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1rwzrvjafOk",
        "outputId": "57abc635-9e9d-4038-c43d-5af10dc6b404"
      },
      "source": [
        "!cd ctcdecode/ && pip install ."
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/ctcdecode\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Building wheels for collected packages: ctcdecode\n",
            "  Building wheel for ctcdecode (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ctcdecode: filename=ctcdecode-1.0.3-cp37-cp37m-linux_x86_64.whl size=13241320 sha256=c287d38830b53aaad8f3984ab2d0c621c7caabd08758821e3be8816d836d9322\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gtuh7b9h/wheels/da/bb/b4/233de9fd7927245208e27bcf688bf5680ae3f3874be2895eef\n",
            "Successfully built ctcdecode\n",
            "Installing collected packages: ctcdecode\n",
            "Successfully installed ctcdecode-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_iagxiFmhfC",
        "outputId": "6de599d9-8a2f-4866-9896-4c016e595514"
      },
      "source": [
        "!wget -cO - 'https://drive.google.com/file/d/1jcNOI3jb4GkixA_wuNCIGz-Qjc9OmdxH/view?usp=sharing' > speechrecognition.zip"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-27 09:35:24--  https://drive.google.com/file/d/1jcNOI3jb4GkixA_wuNCIGz-Qjc9OmdxH/view?usp=sharing\n",
            "Resolving drive.google.com (drive.google.com)... 172.217.15.78, 2607:f8b0:4004:810::200e\n",
            "Connecting to drive.google.com (drive.google.com)|172.217.15.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                       [ <=>                ]  64.79K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2021-10-27 09:35:24 (10.7 MB/s) - written to stdout [66348]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdl0J6krKI8H",
        "outputId": "e55a94bd-9641-4abf-c2e0-c556ee3d6c76"
      },
      "source": [
        "!unzip speechrecognition.zip"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  speechrecognition.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of speechrecognition.zip or\n",
            "        speechrecognition.zip.zip, and cannot find speechrecognition.zip.ZIP, period.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHV68Ykn0UYG",
        "outputId": "802f2e9e-14fd-4794-925e-f2c1ddcc9ec2"
      },
      "source": [
        "!wget -cO - 'https://drive.google.com/file/d/1zgdJ_0QN2SDHBb-nUdJhjvCRmYnR-Az5/view?usp=sharing' > speechrecognition.ckpt"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-27 09:35:25--  https://drive.google.com/file/d/1zgdJ_0QN2SDHBb-nUdJhjvCRmYnR-Az5/view?usp=sharing\n",
            "Resolving drive.google.com (drive.google.com)... 172.217.15.78, 2607:f8b0:4004:810::200e\n",
            "Connecting to drive.google.com (drive.google.com)|172.217.15.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                       [ <=>                ]  64.44K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2021-10-27 09:35:25 (10.5 MB/s) - written to stdout [65983]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LI4uZhq8V4rV"
      },
      "source": [
        "## Fetch Audio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "AFKQVMLFV6fF",
        "outputId": "669b9f2a-d828-4f3f-e64a-99538b6c9c38"
      },
      "source": [
        "from pytube import YouTube\n",
        "\n",
        "url = 'https://youtu.be/HtSuA80QTyo'\n",
        "\n",
        "yt = YouTube(url)\n",
        "print(f'Downloading {yt.title}')\n",
        "audio = yt.streams.get_by_itag(251)\n",
        "audio.download('.')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 1. Algorithmic Thinking, Peak Finding\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/./1 Algorithmic Thinking Peak Finding.webm'"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f28PpnU2XpQZ"
      },
      "source": [
        "# Convert to wav"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9ITS-5hXsQe",
        "outputId": "dc808dd0-ac58-461f-8d6e-1f9162ed8137"
      },
      "source": [
        "import librosa\n",
        "from scipy.io import wavfile\n",
        "\n",
        "aud = librosa.load('1 Algorithmic Thinking Peak Finding.webm')\n",
        "wavfile.write('wavAudio.wav', aud[1], aud[0])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ez2SFVsW0o9"
      },
      "source": [
        "## Creating JSON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubDaAiqvWt9x"
      },
      "source": [
        "import json\n",
        "\n",
        "data = []\n",
        "\n",
        "with open('captions_data.json', 'r') as f:\n",
        "    captions_data = json.load(f)\n",
        "\n",
        "for event in captions_data['events']:\n",
        "    sample = dict()\n",
        "    sample[\"key\"] = str(event['tStartMs']) + '.wav'\n",
        "    sample[\"text\"] = event['segs'][0]['utf8']\n",
        "    data.append(sample)\n",
        "\n",
        "\n",
        "with open('dataset.json', 'w') as f:\n",
        "    json.dump(data, f, indent=4)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2LPg-Y6XYOX"
      },
      "source": [
        "## Chopping clips"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I54pF48YWda8"
      },
      "source": [
        "!mkdir clips"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBczDSWvYThb"
      },
      "source": [
        "with open('captions_data.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "aud = librosa.load('wavAudio.wav')\n",
        "\n",
        "for event in data['events']:\n",
        "    start_index = event['tStartMs'] * 1e-3 * aud[1]\n",
        "    end_index = (event['tStartMs'] + event['dDurationMs']) * 1e-3 * aud[1]\n",
        "\n",
        "    start_index, end_index = int(start_index), int(end_index)\n",
        "\n",
        "    chopped_sample = aud[0][start_index:end_index]\n",
        "    wavfile.write('clips/{}.wav'.format(event['tStartMs']), aud[1], chopped_sample)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayj0h97QZbdi"
      },
      "source": [
        "## Cleaning Dataset.json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UU56RXRNZdul"
      },
      "source": [
        "def clean_data(dataset_path):\n",
        "\n",
        "    with open(dataset_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    for event in data:\n",
        "        sentence = event['text']\n",
        "        sentence = sentence.replace('\\n', ' ')\n",
        "        sentence = remove_caps(sentence)\n",
        "        sentence = remove_special_chars(sentence)\n",
        "        sentence = sentence.lower()\n",
        "        event['text'] = sentence\n",
        "\n",
        "    with open(dataset_path, 'w') as f:\n",
        "        json.dump(data, f, indent=4)\n",
        "\n",
        "\n",
        "def remove_caps(string):\n",
        "    string = string.split()\n",
        "    for word in string:\n",
        "        if(word.isupper()):\n",
        "            string.remove(word)\n",
        "    string = \" \".join(string)\n",
        "    return string\n",
        "\n",
        "def remove_special_chars(string):\n",
        "\n",
        "    removables = ['.', ',', ';', '\"', '\\'', ':', '<', '>', '?', '/', '\\\\', '[', ']', '{', '}', '-', '_', '+', '=', '(', ')', '!', '@', '#', '$', '%', '^', '&', '*', '~', '`']\n",
        "\n",
        "    string = list(string)\n",
        "\n",
        "    for ch in string:\n",
        "        if ch in removables:\n",
        "            string.remove(ch)\n",
        "\n",
        "    string = \"\".join(string)\n",
        "    return string"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaTilLvFZ89B"
      },
      "source": [
        "clean_data('dataset.json')"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SXiK0ZJnNOo"
      },
      "source": [
        "## Train-Dev-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXO4ERqjf0q3"
      },
      "source": [
        "def train_dev_test(file_path, train_size = 0.8, dev_size = 0.1):\n",
        "  with open(file_path, 'r') as f:\n",
        "    ds = json.load(f)\n",
        "\n",
        "  n = len(ds)\n",
        "\n",
        "  train_ind = int(n*train_size)\n",
        "  dev_ind = int(train_ind + n*dev_size)\n",
        "\n",
        "  train_set = ds[:train_ind]\n",
        "  dev_set = ds[train_ind:dev_ind]\n",
        "  test_set = ds[dev_ind:]\n",
        "\n",
        "  with open('train.json', 'w') as f:\n",
        "    json.dump(train_set, f, indent = 4)\n",
        "\n",
        "  with open('dev.json', 'w') as f:\n",
        "    json.dump(dev_set, f, indent = 4)\n",
        "\n",
        "  with open('test.json', 'w') as f:\n",
        "    json.dump(test_set, f, indent = 4)\n",
        "\n",
        "\n",
        "train_dev_test('dataset.json')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSyXQlNqhFtJ"
      },
      "source": [
        "import torch\n",
        "\n",
        "class TextProcess:\n",
        "\tdef __init__(self):\n",
        "\t\tchar_map_str = \"\"\"\n",
        "\t\t' 0\n",
        "\t\t<SPACE> 1\n",
        "\t\ta 2\n",
        "\t\tb 3\n",
        "\t\tc 4\n",
        "\t\td 5\n",
        "\t\te 6\n",
        "\t\tf 7\n",
        "\t\tg 8\n",
        "\t\th 9\n",
        "\t\ti 10\n",
        "\t\tj 11\n",
        "\t\tk 12\n",
        "\t\tl 13\n",
        "\t\tm 14\n",
        "\t\tn 15\n",
        "\t\to 16\n",
        "\t\tp 17\n",
        "\t\tq 18\n",
        "\t\tr 19\n",
        "\t\ts 20\n",
        "\t\tt 21\n",
        "\t\tu 22\n",
        "\t\tv 23\n",
        "\t\tw 24\n",
        "\t\tx 25\n",
        "\t\ty 26\n",
        "\t\tz 27\n",
        "\t\t\"\"\"\n",
        "\t\tself.char_map = {}\n",
        "\t\tself.index_map = {}\n",
        "\t\tfor line in char_map_str.strip().split('\\n'):\n",
        "\t\t\tch, index = line.split()\n",
        "\t\t\tself.char_map[ch] = int(index)\n",
        "\t\t\tself.index_map[int(index)] = ch\n",
        "\t\tself.index_map[1] = ' '\n",
        "\n",
        "\tdef text_to_int_sequence(self, text):\n",
        "\t\t\"\"\" Use a character map and convert text to an integer sequence \"\"\"\n",
        "\t\tint_sequence = []\n",
        "\t\tfor c in text:\n",
        "\t\t\tif c == ' ':\n",
        "\t\t\t\tch = self.char_map['<SPACE>']\n",
        "\t\t\telse:\n",
        "\t\t\t\tch = self.char_map[c]\n",
        "\t\t\tint_sequence.append(ch)\n",
        "\t\treturn int_sequence\n",
        "\n",
        "\tdef int_to_text_sequence(self, labels):\n",
        "\t\t\"\"\" Use a character map and convert integer labels to an text sequence \"\"\"\n",
        "\t\tstring = []\n",
        "\t\tfor i in labels:\n",
        "\t\t\tstring.append(self.index_map[i])\n",
        "\t\treturn ''.join(string).replace('<SPACE>', ' ')\n",
        "\n",
        "\n",
        "textprocess = TextProcess()\n",
        "\n",
        "#THIS\n",
        "def GreedyDecoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True):\n",
        "\targ_maxes = torch.argmax(output, dim=2)\n",
        "\tdecodes = []\n",
        "\ttargets = []\n",
        "\tfor i, args in enumerate(arg_maxes):\n",
        "\t\tdecode = []\n",
        "\t\ttargets.append(textprocess.int_to_text_sequence(\n",
        "\t\t\t\tlabels[i][:label_lengths[i]].tolist()))\n",
        "\t\tfor j, index in enumerate(args):\n",
        "\t\t\tif index != blank_label:\n",
        "\t\t\t\tif collapse_repeated and j != 0 and index == args[j -1]:\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\tdecode.append(index.item())\n",
        "\t\tdecodes.append(textprocess.int_to_text_sequence(decode))\n",
        "\treturn decodes, targets"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BsWQ5EIhIuj"
      },
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# NOTE: add time stretch\n",
        "class SpecAugment(nn.Module):\n",
        "\n",
        "    def __init__(self, rate, policy=3, freq_mask=15, time_mask=35):\n",
        "        super(SpecAugment, self).__init__()\n",
        "\n",
        "        self.rate = rate\n",
        "\n",
        "        self.specaug = nn.Sequential(\n",
        "            torchaudio.transforms.FrequencyMasking(freq_mask_param=freq_mask),\n",
        "            torchaudio.transforms.TimeMasking(time_mask_param=time_mask)\n",
        "        )\n",
        "\n",
        "        self.specaug2 = nn.Sequential(\n",
        "            torchaudio.transforms.FrequencyMasking(freq_mask_param=freq_mask),\n",
        "            torchaudio.transforms.TimeMasking(time_mask_param=time_mask),\n",
        "            torchaudio.transforms.FrequencyMasking(freq_mask_param=freq_mask),\n",
        "            torchaudio.transforms.TimeMasking(time_mask_param=time_mask)\n",
        "        )\n",
        "\n",
        "        policies = { 1: self.policy1, 2: self.policy2, 3: self.policy3 }\n",
        "        self._forward = policies[policy]\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._forward(x)\n",
        "\n",
        "    def policy1(self, x):\n",
        "        probability = torch.rand(1, 1).item()\n",
        "        if self.rate > probability:\n",
        "            return  self.specaug(x)\n",
        "        return x\n",
        "\n",
        "    def policy2(self, x):\n",
        "        probability = torch.rand(1, 1).item()\n",
        "        if self.rate > probability:\n",
        "            return  self.specaug2(x)\n",
        "        return x\n",
        "\n",
        "    def policy3(self, x):\n",
        "        probability = torch.rand(1, 1).item()\n",
        "        if probability > 0.5:\n",
        "            return self.policy1(x)\n",
        "        return self.policy2(x)\n",
        "\n",
        "\n",
        "class LogMelSpec(nn.Module):\n",
        "\n",
        "    def __init__(self, sample_rate=8000, n_mels=128, win_length=160, hop_length=80):\n",
        "        super(LogMelSpec, self).__init__()\n",
        "        self.transform = torchaudio.transforms.MelSpectrogram(\n",
        "                            sample_rate=sample_rate, n_mels=n_mels,\n",
        "                            win_length=win_length, hop_length=hop_length)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.transform(x)  # mel spectrogram\n",
        "        x = np.log(x + 1e-14)  # logrithmic, add small value to avoid inf\n",
        "        return x\n",
        "\n",
        "\n",
        "def get_featurizer(sample_rate, n_feats=81):\n",
        "    return LogMelSpec(sample_rate=sample_rate, n_mels=n_feats,  win_length=160, hop_length=80)\n",
        "\n",
        "\n",
        "class Data(torch.utils.data.Dataset):\n",
        "\n",
        "    # this makes it easier to be ovveride in argparse\n",
        "    parameters = {\n",
        "        \"sample_rate\": 8000, \"n_feats\": 81,\n",
        "        \"specaug_rate\": 0.5, \"specaug_policy\": 3,\n",
        "        \"time_mask\": 70, \"freq_mask\": 15 \n",
        "    }\n",
        "\n",
        "    def __init__(self, json_path, sample_rate, n_feats, specaug_rate, specaug_policy,\n",
        "                time_mask, freq_mask, valid=False, shuffle=True, text_to_int=True, log_ex=True):\n",
        "        self.log_ex = log_ex\n",
        "        self.text_process = TextProcess()\n",
        "\n",
        "        print(\"Loading data json file from\", json_path)\n",
        "        self.data = pd.read_json(json_path, lines=True)\n",
        "\n",
        "        if valid:\n",
        "            self.audio_transforms = torch.nn.Sequential(\n",
        "                LogMelSpec(sample_rate=sample_rate, n_mels=n_feats,  win_length=160, hop_length=80)\n",
        "            )\n",
        "        else:\n",
        "            self.audio_transforms = torch.nn.Sequential(\n",
        "                LogMelSpec(sample_rate=sample_rate, n_mels=n_feats,  win_length=160, hop_length=80),\n",
        "                SpecAugment(specaug_rate, specaug_policy, freq_mask, time_mask)\n",
        "            )\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.item()\n",
        "\n",
        "        try:\n",
        "            file_path = self.data.key.iloc[idx]\n",
        "            waveform, _ = torchaudio.load(file_path)\n",
        "            label = self.text_process.text_to_int_sequence(self.data['text'].iloc[idx])\n",
        "            spectrogram = self.audio_transforms(waveform) # (channel, feature, time)\n",
        "            spec_len = spectrogram.shape[-1] // 2\n",
        "            label_len = len(label)\n",
        "            if spec_len < label_len:\n",
        "                raise Exception('spectrogram len is bigger then label len')\n",
        "            if spectrogram.shape[0] > 1:\n",
        "                raise Exception('dual channel, skipping audio file %s'%file_path)\n",
        "            if spectrogram.shape[2] > 1650:\n",
        "                raise Exception('spectrogram to big. size %s'%spectrogram.shape[2])\n",
        "            if label_len == 0:\n",
        "                raise Exception('label len is zero... skipping %s'%file_path)\n",
        "        except Exception as e:\n",
        "            if self.log_ex:\n",
        "                print(str(e), file_path)\n",
        "            return self.__getitem__(idx - 1 if idx != 0 else idx + 1)  \n",
        "        return spectrogram, label, spec_len, label_len\n",
        "\n",
        "    def describe(self):\n",
        "        return self.data.describe()\n",
        "\n",
        "\n",
        "def collate_fn_padd(data):\n",
        "    '''\n",
        "    Padds batch of variable length\n",
        "\n",
        "    note: it converts things ToTensor manually here since the ToTensor transform\n",
        "    assume it takes in images rather than arbitrary tensors.\n",
        "    '''\n",
        "    # print(data)\n",
        "    spectrograms = []\n",
        "    labels = []\n",
        "    input_lengths = []\n",
        "    label_lengths = []\n",
        "    for (spectrogram, label, input_length, label_length) in data:\n",
        "        if spectrogram is None:\n",
        "            continue\n",
        "       # print(spectrogram.shape)\n",
        "        spectrograms.append(spectrogram.squeeze(0).transpose(0, 1))\n",
        "        labels.append(torch.Tensor(label))\n",
        "        input_lengths.append(input_length)\n",
        "        label_lengths.append(label_length)\n",
        "\n",
        "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
        "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
        "    input_lengths = input_lengths\n",
        "    # print(spectrograms.shape)\n",
        "    label_lengths = label_lengths\n",
        "    # ## compute mask\n",
        "    # mask = (batch != 0).cuda(gpu)\n",
        "    # return batch, lengths, mask\n",
        "    return spectrograms, labels, input_lengths, label_lengths"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQbXsCRh6MYX"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3JrMyc15u1C"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "class ActDropNormCNN1D(nn.Module):\n",
        "    def __init__(self, n_feats, dropout, keep_shape=False):\n",
        "        super(ActDropNormCNN1D, self).__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.norm = nn.LayerNorm(n_feats)\n",
        "        self.keep_shape = keep_shape\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)\n",
        "        # x = self.norm(self.dropout(F.gelu(x)))\n",
        "        x = self.dropout(F.gelu(self.norm(x)))\n",
        "        if self.keep_shape:\n",
        "            return x.transpose(1, 2)\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "\n",
        "class SpeechRecognition(nn.Module):\n",
        "    hyper_parameters = {\n",
        "        \"num_classes\": 29,\n",
        "        \"n_feats\": 81,\n",
        "        \"dropout\": 0.1,\n",
        "        \"hidden_size\": 1024,\n",
        "        \"num_layers\": 1\n",
        "    }\n",
        "\n",
        "    def __init__(self, hidden_size, num_classes, n_feats, num_layers, dropout):\n",
        "        super(SpeechRecognition, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(n_feats, n_feats, 10, 2, padding=10//2),\n",
        "            ActDropNormCNN1D(n_feats, dropout),\n",
        "        )\n",
        "        self.dense = nn.Sequential(\n",
        "            nn.Linear(n_feats, 128),\n",
        "            nn.LayerNorm(128),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.LayerNorm(128),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "        self.lstm = nn.LSTM(input_size=128, hidden_size=hidden_size,\n",
        "                            num_layers=num_layers, dropout=0.0,\n",
        "                            bidirectional=False)\n",
        "        self.layer_norm2 = nn.LayerNorm(hidden_size)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.final_fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def _init_hidden(self, batch_size):\n",
        "        n, hs = self.num_layers, self.hidden_size\n",
        "        return (torch.zeros(n*1, batch_size, hs),\n",
        "                torch.zeros(n*1, batch_size, hs))\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        x = x.squeeze(1)  # batch, feature, time\n",
        "        x = self.cnn(x) # batch, time, feature\n",
        "        x = self.dense(x) # batch, time, feature\n",
        "        x = x.transpose(0, 1) # time, batch, feature\n",
        "        out, (hn, cn) = self.lstm(x, hidden)\n",
        "        x = self.dropout2(F.gelu(self.layer_norm2(out)))  # (time, batch, n_class)\n",
        "        return self.final_fc(x), (hn, cn)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-3-hwpp58i7"
      },
      "source": [
        "import os\n",
        "import ast\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from pytorch_lightning.core.lightning import LightningModule\n",
        "from pytorch_lightning import Trainer\n",
        "from argparse import ArgumentParser\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "class SpeechModule(LightningModule):\n",
        "\n",
        "    def __init__(self, model, args):\n",
        "        super(SpeechModule, self).__init__()\n",
        "        self.model = model\n",
        "        self.criterion = nn.CTCLoss(blank=28, zero_infinity=True)\n",
        "        self.args = args\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        return self.model(x, hidden)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        self.optimizer = optim.AdamW(self.model.parameters(), self.args.learning_rate)\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                                        self.optimizer, mode='min',\n",
        "                                        factor=0.50, patience=6)\n",
        "        return [self.optimizer], [self.scheduler]\n",
        "\n",
        "    def step(self, batch):\n",
        "        spectrograms, labels, input_lengths, label_lengths = batch \n",
        "        bs = spectrograms.shape[0]\n",
        "        hidden = self.model._init_hidden(bs)\n",
        "        hn, c0 = hidden[0].to(self.device), hidden[1].to(self.device)\n",
        "        output, _ = self(spectrograms, (hn, c0))\n",
        "        output = F.log_softmax(output, dim=2)\n",
        "        loss = self.criterion(output, labels, input_lengths, label_lengths)\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss = self.step(batch)\n",
        "        logs = {'loss': loss, 'lr': self.optimizer.param_groups[0]['lr'] }\n",
        "        return {'loss': loss, 'log': logs}\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        d_params = Data.parameters\n",
        "        d_params.update(self.args.dparams_override)\n",
        "        train_dataset = Data(json_path=self.args.train_file, **d_params)\n",
        "        return DataLoader(dataset=train_dataset,\n",
        "                            batch_size=self.args.batch_size,\n",
        "                            num_workers=self.args.data_workers,\n",
        "                            pin_memory=True,\n",
        "                            collate_fn=collate_fn_padd)\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss = self.step(batch)\n",
        "        return {'val_loss': loss}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
        "        self.scheduler.step(avg_loss)\n",
        "        tensorboard_logs = {'val_loss': avg_loss}\n",
        "        return {'val_loss': avg_loss, 'log': tensorboard_logs}\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        d_params = Data.parameters\n",
        "        d_params.update(self.args.dparams_override)\n",
        "        test_dataset = Data(json_path=self.args.valid_file, **d_params, valid=True)\n",
        "        return DataLoader(dataset=test_dataset,\n",
        "                            batch_size=self.args.batch_size,\n",
        "                            num_workers=self.args.data_workers,\n",
        "                            collate_fn=collate_fn_padd,\n",
        "                            pin_memory=True)\n",
        "\n",
        "\n",
        "def checkpoint_callback(args):\n",
        "    return ModelCheckpoint(\n",
        "        filepath=args.save_model_path,\n",
        "        save_top_k=True,\n",
        "        verbose=True,\n",
        "        monitor='val_loss',\n",
        "        mode='min',\n",
        "        prefix=''\n",
        "    )\n",
        "\n",
        "def main(args):\n",
        "    h_params = SpeechRecognition.hyper_parameters\n",
        "    h_params.update(args.hparams_override)\n",
        "    model = SpeechRecognition(**h_params)\n",
        "\n",
        "    if args.load_model_from:\n",
        "        speech_module = SpeechModule.load_from_checkpoint(args.load_model_from, model=model, args=args)\n",
        "    else:\n",
        "        speech_module = SpeechModule(model, args)\n",
        "\n",
        "    logger = TensorBoardLogger(args.logdir, name='speech_recognition')\n",
        "    trainer = Trainer(logger=logger)\n",
        "\n",
        "    trainer = Trainer(\n",
        "        max_epochs=args.epochs, gpus=args.gpus,\n",
        "        num_nodes=args.nodes, distributed_backend=None,\n",
        "        logger=logger, gradient_clip_val=1.0,\n",
        "        val_check_interval=args.valid_every,\n",
        "        checkpoint_callback=checkpoint_callback(args),\n",
        "        resume_from_checkpoint=args.resume_from_checkpoint\n",
        "    )\n",
        "    trainer.fit(speech_module)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzDRYGu-1rEg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "outputId": "e0a01304-9e84-44de-a428-c35b29afe4c9"
      },
      "source": [
        "# parser = ArgumentParser()\n",
        "# #distributed training setup\n",
        "# parser.add_argument('-n', '--nodes', default=1, type=int, help='number of data loading workers')\n",
        "# parser.add_argument('-g', '--gpus', default=1, type=int, help='number of gpus per node')\n",
        "# parser.add_argument('-w', '--data_workers', default=0, type=int,\n",
        "#                     help='n data loading workers, default 0 = main process only')\n",
        "# parser.add_argument('-db', '--dist_backend', default='ddp', type=str,\n",
        "#                     help='which distributed backend to use. defaul ddp')\n",
        "\n",
        "# #train and valid\n",
        "# parser.add_argument('--train_file', default=None, required=False, type=str,\n",
        "#                     help='json file to load training data')\n",
        "# parser.add_argument('--valid_file', default=None, required=False, type=str,\n",
        "#                     help='json file to load testing data')\n",
        "# parser.add_argument('--valid_every', default=1000, required=False, type=int,\n",
        "#                     help='valid after every N iteration')\n",
        "\n",
        "# #dir and path for models and logs\n",
        "# parser.add_argument('--save_model_path', default=None, required=False, type=str,\n",
        "#                     help='path to save model')\n",
        "# parser.add_argument('--load_model_from', default=None, required=False, type=str,\n",
        "#                     help='path to load a pretrain model to continue training')\n",
        "# parser.add_argument('--resume_from_checkpoint', default=None, required=False, type=str,\n",
        "#                     help='check path to resume from')\n",
        "# parser.add_argument('--logdir', default='tb_logs', required=False, type=str,\n",
        "#                     help='path to save logs')\n",
        "\n",
        "# #general\n",
        "# parser.add_argument('--epochs', default=10, type=int, help='number of total epochs to run')\n",
        "# parser.add_argument('--batch_size', default=64, type=int, help='size of batch')\n",
        "# parser.add_argument('--learning_rate', default=1e-3, type=float, help='learning rate')\n",
        "# parser.add_argument('--pct_start', default=0.3, type=float, help='percentage of growth phase in one cycle')\n",
        "# parser.add_argument('--div_factor', default=100, type=int, help='div factor for one cycle')\n",
        "# parser.add_argument(\"--hparams_override\", default=\"{}\", type=str, required=False,\n",
        "# help='override the hyper parameters, should be in form of dict. ie. {\"attention_layers\": 16 }')\n",
        "# parser.add_argument(\"--dparams_override\", default=\"{}\", type=str, required=False,\n",
        "# help='override the data parameters, should be in form of dict. ie. {\"sample_rate\": 8000 }')\n",
        "\n",
        "# args = parser.parse_args()\n",
        "# args.hparams_override = ast.literal_eval(args.hparams_override)\n",
        "# args.dparams_override = ast.literal_eval(args.dparams_override)\n",
        "\n",
        "\n",
        "# if args.save_model_path:\n",
        "#     if not os.path.isdir(os.path.dirname(args.save_model_path)):\n",
        "#         raise Exception(\"the directory for path {} does not exist\".format(args.save_model_path))\n",
        "\n",
        "class Args:\n",
        "  def __init__(self):\n",
        "    self.nodes = 1\n",
        "    self.gpus = 1\n",
        "    self.data_workers = 0\n",
        "    self.dist_backend = 'ddp'\n",
        "    self.train_file = 'train.json'\n",
        "    self.valid_file = 'dev.json'\n",
        "    self.valid_every = 1000\n",
        "    self.save_model_path = 'model.ckpt'\n",
        "    self.load_model_from = 'speechrecognition.ckpt'\n",
        "    self.resume_from_checkpoint = False\n",
        "    self.logdir = 'tb_logs'\n",
        "    self.epochs = 10\n",
        "    self.batch_size = 64\n",
        "    self.learning_rate = 1e-3\n",
        "    self.pct_start = 0.3\n",
        "    self.div_factor = 100\n",
        "    self.hparams_override = {}\n",
        "    self.dparams_override = {}\n",
        "\n",
        "args = Args()\n",
        "# args.train_file = 'train.json'\n",
        "# args.valid_file = 'dev.json'\n",
        "# args.save_model_path = 'speechrecognition_new.ckpt'\n",
        "# args.load_model_from = 'speechrecognition.ckpt'\n",
        "\n",
        "main(args)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnpicklingError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-fb1a979c2cbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;31m# args.load_model_from = 'speechrecognition.ckpt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-44-7de2a1f98170>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_from\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mspeech_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpeechModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_from\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mspeech_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpeechModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/saving.py\u001b[0m in \u001b[0;36mload_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhparams_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/cloud_io.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path_or_url, map_location)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_filesystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    606\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    775\u001b[0m             \"functionality.\")\n\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m     \u001b[0mmagic_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmagic_number\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mMAGIC_NUMBER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid magic number; corrupt file?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '<'."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr3nis64IYk5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}